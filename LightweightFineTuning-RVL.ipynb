{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851e1ea",
   "metadata": {},
   "source": [
    "* PEFT technique: \n",
    "    - For the Parameter-Efficient Fine-Tuning (PEFT) technique, I utilized the Lora method.\n",
    "\n",
    "* Model: \n",
    "    - The base model used for fine-tuning is the GPT-2 model, which is a transformer-based language model pre-trained on a large corpus of text data. GPT-2 is well-suited for various natural language processing tasks, including sequence classification, due to its powerful contextual understanding capabilities.\n",
    "\n",
    "* Evaluation approach: \n",
    "    - The evaluation approach involves assessing the performance of the fine-tuned model using accuracy as the primary evaluation metric. Accuracy measures the proportion of correctly classified instances out of the total number of instances in the evaluation dataset. Additionally, the evaluation includes calculating the evaluation loss to understand the model's performance in terms of prediction confidence.\n",
    "\n",
    "* Fine-tuning dataset: \n",
    "    - The fine-tuning dataset comprises the IMDB dataset, which contains movie reviews labeled with sentiment (positive or negative). This dataset provides a diverse range of textual data suitable for training a sentiment analysis model. Additionally, a subset of the dataset is used to reduce computational resources while still ensuring effective fine-tuning of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "In the cells below, I loaded my chosen pre-trained Hugging Face model and evaluated its performance prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e35e7",
   "metadata": {},
   "source": [
    "### Install & Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e317128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/student/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install the required version of datasets in case you have an older version\n",
    "# You will need to choose \"Kernel > Restart Kernel\" from the menu after executing this cell\n",
    "! pip install -q \"datasets==2.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8a039",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gpt2\"\n",
    "DATASET_NAME = \"imdb\"\n",
    "splits = [\"train\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869c775",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Let's load the dataset and select subset of the dataset for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87e13b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 5000\n",
       " })}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset(DATASET_NAME, split=splits))}\n",
    "\n",
    "# Select subset of the dataset for faster computation\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# Print the dataset \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2778e7",
   "metadata": {},
   "source": [
    "### Pre-process datasets\n",
    "Now we are going to process our datasets by converting all the text into tokens for our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d2b7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# Set pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69812db",
   "metadata": {},
   "source": [
    "Pre-process datasets by converting text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "246a1dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87db77425f6433c92b50b4b76305bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 5000\n",
       " })}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_ds = {}\n",
    "\n",
    "# Tokenize and preprocess dataset splits\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(preprocess_function, batched=True)\n",
    "\n",
    "# Print the tokenized dataset\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8116469",
   "metadata": {},
   "source": [
    "Print one example represented as tokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86244612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1858, 318, 645, 8695, 379, 477, 1022, 6401, 959, 290]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds[\"train\"][0][\"input_ids\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd737c",
   "metadata": {},
   "source": [
    "### Testing how tokenizer and padding works [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a83359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "<|endoftext|>\n",
      "Sentence 1: This is the first sentence.\n",
      "Tokenized: tensor([ 1212,   318,   262,   717,  6827,    13, 50256, 50256])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 0, 0])\n",
      "\n",
      "Sentence 2: And here comes the second one.\n",
      "Tokenized: tensor([ 1870,   994,  2058,   262,  1218,   530,    13, 50256])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 0])\n",
      "\n",
      "Sentence 3: Finally, the last and longest sentence.\n",
      "Tokenized: tensor([11158,    11,   262,   938,   290, 14069,  6827,    13])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.eos_token)\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"This is the first sentence.\",\n",
    "    \"And here comes the second one.\",\n",
    "    \"Finally, the last and longest sentence.\"\n",
    "]\n",
    "\n",
    "# Tokenize sentences\n",
    "tokenized_sentences = tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# Print tokenized sequences\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n",
    "    print(\"Tokenized:\", tokenized_sentences['input_ids'][i])\n",
    "    print(\"Attention Mask:\", tokenized_sentences['attention_mask'][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411fc8e",
   "metadata": {},
   "source": [
    "## Load and set up the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d662ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c9ae1552644a0b514713445a60460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d028c08",
   "metadata": {},
   "source": [
    "Set the model's pad token id to match the tokenizer's pad token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24167c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb265c",
   "metadata": {},
   "source": [
    "Ensure that finetuning doesn't effect the base model weights, as we are going to train only the adapter later on using LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3722cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in base_model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40543c98",
   "metadata": {},
   "source": [
    "Print the architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce6ff5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ea234",
   "metadata": {},
   "source": [
    "Print the final linear layer used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f931e",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e0c6d",
   "metadata": {},
   "source": [
    "Define function to compute metrics during evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85c06f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4d4d8",
   "metadata": {},
   "source": [
    "Define the TrainingArguments used as the training configuration, including output directory, learning rate, batch size, and evaluation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a860e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cd205",
   "metadata": {},
   "source": [
    "Next the Trainer initializes the training process with the specified arguments, datasets, tokenizer, and metric computation for the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f16de157",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135451ac",
   "metadata": {},
   "source": [
    "The code below evaluates the foundational model on the evaluation dataset and prints out the evaluation results, including metrics such as evaluation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3706f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 02:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results of foundational model: {'eval_loss': 7.370438098907471, 'eval_accuracy': 0.4986, 'eval_runtime': 173.8013, 'eval_samples_per_second': 28.768, 'eval_steps_per_second': 1.801}\n"
     ]
    }
   ],
   "source": [
    "pretrained_results = pretrain_trainer.evaluate()\n",
    "\n",
    "print(f\"Evaluation results of foundational model: {pretrained_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "In the cells below, I created a PEFT model from my loaded model, run a training loop, and saved the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "# ensure cuda caches is empty\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab79fc9",
   "metadata": {},
   "source": [
    "The code below initializes a base model for sequence classification using the AutoModelForSequenceClassification class from the Hugging Face library, loading the model specified by MODEL_ID and configuring it for binary classification with two labels: \"NEGATIVE\" and \"POSITIVE\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3afcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351b8fa",
   "metadata": {},
   "source": [
    "Set the model's pad token id to match the tokenizer's pad token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01b06786",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b5c9fe",
   "metadata": {},
   "source": [
    "Next I initialize a configuration for Parameter-Efficient Fine-Tuning (PEFT) using the LoraConfig class, specifying parameters such as the regularization factor (r), Lora alpha value (lora_alpha), target modules for applying PEFT (target_modules), Lora dropout rate (lora_dropout), bias type (bias), and the task type (task_type) as sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['c_attn', 'c_proj'],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917cc435",
   "metadata": {},
   "source": [
    "The code below creates a PEFT model by applying Parameter-Efficient Fine-Tuning (PEFT) to the base model using the specified configuration (peft_config). Afterward, it prints the number of trainable parameters in the PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4118f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 814,080 || all params: 125,253,888 || trainable%: 0.6499438963523432\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246894d",
   "metadata": {},
   "source": [
    "Format the training and testing datasets to torch tensors, specifying the columns to include, such as input IDs, attention masks, and labels. This formatting facilitates compatibility with PyTorch-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53280d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_ds[\"test\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee3b57",
   "metadata": {},
   "source": [
    "Initialize training arguments and a Trainer object for fine-tuning the base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097cac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_model_output\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_steps = 50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=50,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a224d",
   "metadata": {},
   "source": [
    "Start training for number of epochs given by \"num_train_epochs\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65dcec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 34:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.409858</td>\n",
       "      <td>0.878600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.401110</td>\n",
       "      <td>0.890400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./lora_model_output/checkpoint-1250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./lora_model_output/checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./lora_model_output/checkpoint-3750 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.5038451108296712, metrics={'train_runtime': 2078.983, 'train_samples_per_second': 7.215, 'train_steps_per_second': 1.804, 'total_flos': 3956893286400000.0, 'train_loss': 0.5038451108296712, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6c62f",
   "metadata": {},
   "source": [
    "Save fine tuned PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f73cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "In the cells below, I loaded the saved PEFT model weights and evaluated the performance of the trained PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4837ae6",
   "metadata": {},
   "source": [
    "This code initializes a PEFT model for sequence classification using the AutoPeftModelForSequenceClassification class. It loads the pretrained PEFT model named, configures it for binary classification with two labels, and transfers it to the available CUDA device if available, otherwise to CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt-lora\", \n",
    "    num_labels=NUM_LABELS, \n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b12ac",
   "metadata": {},
   "source": [
    "Set the model's pad token id to match the tokenizer's pad token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854ddd4",
   "metadata": {},
   "source": [
    "Initialize training arguments and a Trainer object as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/sentiment_analysis\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "finetuned_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce641ae6",
   "metadata": {},
   "source": [
    "Evaluate the fine-tuned model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 03:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the fine-tuned model: {'eval_loss': 0.40110960602760315, 'eval_accuracy': 0.8904, 'eval_runtime': 192.6615, 'eval_samples_per_second': 25.952, 'eval_steps_per_second': 1.625}\n"
     ]
    }
   ],
   "source": [
    "finetuned_results = finetuned_trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results for the fine-tuned model\n",
    "print(\"Evaluation results for the fine-tuned model:\", finetuned_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20258b",
   "metadata": {},
   "source": [
    "Evaluating both the foundational model and the fine-tuned model on the evaluation dataset shows the following results below: \n",
    "\n",
    "For the foundational \"gpt-2\" model:\n",
    "- Evaluation loss: 7.3704\n",
    "- Evaluation accuracy: 49.86%\n",
    "\n",
    "For the fine-tuned model:\n",
    "- Evaluation loss: 0.4011\n",
    "- Evaluation accuracy: 89.04%\n",
    "\n",
    "These results show a significant improvement in accuracy after fine-tuning the model compared to its performance before fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331a682",
   "metadata": {},
   "source": [
    "To see how well the model performs, the function below helps to predict the label for a given input sentence using the fine-tuned PEFT model (lora_model) and returns the predicted label as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fef6cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence: str) -> str:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lora_model.to(device)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get logit predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = lora_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "    return probabilities.argmax().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae08aae",
   "metadata": {},
   "source": [
    "Negative Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33ecf169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'I'm sad and i wanna cry'\n",
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sentence = \"I'm sad and i wanna cry\"\n",
    "predicted_label = predict(sentence)\n",
    "print(f\"Sentence: '{sentence}'\\nPredicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f30776",
   "metadata": {},
   "source": [
    "Positive Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af863367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'I am happy.'\n",
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am happy.\"\n",
    "\n",
    "predicted_label = predict(sentence)\n",
    "print(f\"Sentence: '{sentence}'\\nPredicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57c484",
   "metadata": {},
   "source": [
    "Positive Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5651709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'This movie was so funny.'\n",
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This movie was so funny.\"\n",
    "\n",
    "predicted_label = predict(sentence)\n",
    "print(f\"Sentence: '{sentence}'\\nPredicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68b424",
   "metadata": {},
   "source": [
    "Negative Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cde0ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'This movie was so frustrating.'\n",
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This movie was so frustrating.\"\n",
    "\n",
    "predicted_label = predict(sentence)\n",
    "print(f\"Sentence: '{sentence}'\\nPredicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
